{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Polynomial Regression\n",
    "\n",
    "### A) Use the Auto dataset, find the test $R^2$ score of a linear regression model that predicts the miles per gallon (mpg) from the horsepower.\n",
    "\n",
    "### B) Use polynomial regression to include both the horsepower feature and $(horsepower)^2$ in the regression model. Find the $R^2$ metric. \n",
    "\n",
    "Hint: You can use [numpy.concatenate](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html). For example to add to an array U a column vector $W^2$, we can use X=np.concatenate((U,W**2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score of this model without housrsepower^2 term is 0.6217658811398383\n",
      "The R2 score of this model with housrsepower^2 term is 0.7271031504642004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "AutoData=read_csv('Auto_modify.csv') # read the data\n",
    "#print(type(AutoData))\n",
    "#print(AutoData)\n",
    "X_auto_hp=AutoData.horsepower.values.reshape(-1,1) # define features: horsepower \n",
    "Y_auto_mpg=AutoData.mpg.values.reshape(-1,1) # define label: miles per gallon\n",
    "\n",
    "# add your solution here\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_auto_hp, Y_auto_mpg, random_state=0)\n",
    "\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print('The R2 score of this model without housrsepower^2 term is ' + str(model.score(X_test, Y_test)))\n",
    "\n",
    "X_auto_hp_2 = np.concatenate((X_auto_hp,np.square(AutoData.horsepower.values.reshape(-1,1))),axis = 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_auto_hp_2, Y_auto_mpg, random_state=0)\n",
    "\n",
    "model = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print('The R2 score of this model with housrsepower^2 term is ' + str(model.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)Use KNN regression to predict the miles per gallon(mpg) with K=7, and find $R^2$ metric in the following cases \n",
    "\n",
    "- One feature: Horsepower only\n",
    "\n",
    "- Two features: horsepower and $(horsepower)^2$ \n",
    "\n",
    "Hint: \n",
    "\n",
    "    Create KNN regression object using neighbors.KNeighborsRegressor:\n",
    "\n",
    "    knnRegression = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "\n",
    "    Use the .fit and .score methods as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score of this model without housrsepower^2 term is 0.6674777441714226\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "AutoData=read_csv('Auto_modify.csv')\n",
    "\n",
    "X_auto_hp=AutoData.horsepower.values.reshape(-1,1) # define features: horsepower\n",
    "Y_new = AutoData.mpg.values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_auto_hp, Y_new, random_state=0)\n",
    "\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('The R2 score of this model without housrsepower^2 term is ' + str(model.score(X_test, Y_test)))\n",
    "\n",
    "# X_auto_hp_2 = np.concatenate((X_auto_hp,np.square(AutoData.horsepower.values.reshape(-1,1))),axis = 1)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_auto_hp_2, Y_new, random_state=0)\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=7)\n",
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# print('The R2 score of this model with housrsepower^2 term is ' + str(model.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMMENT on your results on (E) and (F): which model performs better? How does performance change when adding the quadratic feature?\n",
    "\n",
    "1. The second one is slightly better, but it is meaningless. Because when it comes to knn model, addiing the quadratic feature will not be able to distinguish the different distance between different kinds, just waste of time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2: Regularization\n",
    "\n",
    "### A) Use the Boston dataset, and use Ridge regression model with tuning parameter set to 100 (alpha =100). Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "###  B) Use Lasso regression instead of Ridge regression, also set the tuning parameter to 100. Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "### C) Change the tuning parameter of the Lasso model to a very low value (alpha =0.001). What is the $R^2$ score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score of Ridge with alpha =100 is 0.5925358036157627\n",
      "The number of non zero coefficients is 13\n",
      " \n",
      "The R2 score of Lasso with alpha =100 is 0.11866916175527807\n",
      "The number of non zero coefficients is 2\n",
      " \n",
      "The R2 score of Ridge with alpha =0.001 is 0.6350353125168686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_boston()\n",
    "X=dataset.data\n",
    "Y=dataset.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state= 0)\n",
    "\n",
    "model = Ridge(alpha= 100)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "print( 'The R2 score of Ridge with alpha =100 is '+ str( model.score(X_test,Y_test)))\n",
    "print('The number of non zero coefficients is ' + str(np.where(model.coef_ != 0)[0].shape[0]) )\n",
    "print(' ')\n",
    "\n",
    "model2 = Lasso(alpha=100)\n",
    "model2.fit(X_train, Y_train)\n",
    "\n",
    "print( 'The R2 score of Lasso with alpha =100 is '+ str( model2.score(X_test,Y_test)))\n",
    "print('The number of non zero coefficients is ' + str(np.where(model2.coef_ != 0)[0].shape[0]) )\n",
    "print(' ')\n",
    "\n",
    "model3 = Lasso(alpha=0.001)\n",
    "model3.fit(X_train, Y_train)\n",
    "\n",
    "print( 'The R2 score of Ridge with alpha =0.001 is '+ str( model3.score(X_test,Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### D) Comment on your result. In this problem, do all feature seem important in making predictions?\n",
    "1. In this case we can see, the selection of alpha is very important, because it strongly affects the performance of these models. Firstly, if the alpha is too big, many features will lost it's power in predicting the result, because the loss function will tend to diminish the big coefficients, and finally the model becomes underfitted. But if the alpha is too small, then the model will become the normal linear regression. In this case, we can see, not all the features are important. Only the feature with non-zero coefficients can be reagared as useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
